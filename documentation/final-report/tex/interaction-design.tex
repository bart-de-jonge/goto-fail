\section{Interaction Design}
While designing our application, we performed several user tests. The user testing aims to improve the interaction of the application with the user. Most of the time, an application is made and the interaction between the user and application is far from optimal. Developers often forget that they are not the ones using the application when it is done. Some things might be clear to the developer, but not to the user. We are trying to improve this by testing our application with the users during development. This kind of testing can greatly improve the way users interact with your application and results in a better end-product.
\subsection{Method}
All applications are tying to solve a specific problem. When an application has good interaction design, the way the user solves this problem is easy and clear. We want to ensure that the user is able to easily solve the problem or perform a task. It should not be the case that a user gets lost in the application and just gives up. We would like to know what makes an application user friendly. What is bad to do, what is good to do. The way the users work with your application depends greatly on the way the users interact with it. If users don't like the way to interact with the application, they will not use it very much. You want to build the interface of the application to the needs of the user, this way, the user is able to interact in a way that he or she expects.\\

Our application consists of several parts, firstly the scripting application and secondly the web server. Both parts of our application need user tests. The one that needs most testing is the scripting application, since the other is a web view that follows the specification of Google's material design. A lot of thought has gone into material design, so we think that we need to focus on the scripting application for our user tests. We started summing up the main tasks we want a user to be able to perform while using our application. This was the core of our user test. The core consists of adding shots to a project, checking collisions between all the shots and modifying the shots. We also have some smaller features next to this, but this is the core of our application. Once we had all this information, we started filling in the gaps between these actions. Some actions require preceding tasks be performed to complete the action itself. For instance, when adding a shot, you will have to create a project first. When you have filled in the gaps, you can set up a document with the instructions for the user to use during the test. We were looking specifically for the things that a user would expect to see in the application. If things are where the user thinks they are, the positioning is correct. We would like to know what is going on inside the head of the user while working with the application, because of this, we ask the test subjects to use the think aloud protocol. We are now able to hear what the user thinks about our application.\\

Our test subjects should be similar to the end users of the product, because of this, we chose to use members from another context project group, from the same context. The group members are slightly familiar with all the processes inside Polycast and inside a production. We didn't want to have completely random people working with our application, since that is not our target audience. The audience has experience with cameras, scripting and movie/concert production.
\subsection{Results}
Upon opening the application, the user is presented with a choice, create a new project or open an existing one. The users were surprised by the choice and proceeded creating a new project. Upon creating a new project, the users find the division between the fields and boxes nice, it is clean and ordered. One of the users assumed that the description field was optional. It is not completely clear what seconds per count means. It is annoying that the text is cut off with the three dots, this happens throughout the entire scripting application. It is not clear at all that a camera type has to be created before creating cameras, this should be added.\\

Now for creating new shots, description is again required, this is annoying. It is unclear what start and end mean, it is also unclear what the type/format of the input should be. For the rest adding a shot is very clear and intuitive. When only clicking a shot there is a chance that the shot collapses, this is really weird. Dragging on the other hand works really good, it is very clear and accurate to use. Resizing is also easy. When changing information in the shot, it is very nice to see it update immediately! You don't even have to open a window or a dialog, this is so easy! Adding a directorshot is almost the same as adding a camerashot, except that the new fields, padding before and after, have no clear meaning. The generate all shots button is easy to locate. Users immediately notice when two shots are colliding. Because of the dragging functionality all the collisions are easily fixable. It is very weird that you cannot see padding before and after each shot. Changing the color of the application is simple, the button is where you expect it. Uploading the project to the webserver is  easy. All the buttons are located where you would expect them, just like every other big application nowadays.\\

On the web server, navigating is easily done, all the pages are in the side-bar. Opening the detail view of a shot is easy, it is clickable. It also disappears after some time. When trying to advance the current count in the shot-caller view, it is not completely clear where to click. The buttons don't look like buttons, this should be improved.
\subsection{Conclusion and Discussion}
During the user tests we gathered good feedback. Because we are already working on the application for quite some time, we often overlook the simple stuff that is unclear. An example is the text that is too long for the space it has. Users need clear information, not information that is missing or cut off. Some things are really basic, like the appearance of the button. These are small but easily fixable issues. Most of these issues are already fixed, but the more complicated problems require a bit more time to resolve. In conclusion, the user tests were really handy, the feedback was quite useful. Next time, we would plan multiple of these sessions. Since an application is ever-changing, user testing should also be performed multiple times. We also would have wanted to have a real end user test our project, but receiving feedback or even a reply was hard. We think that if there was a session with the real end-user, the feedback would be even more useful, since they will have/want to work with the application on a daily basis. Since this was not possible, we are satisfied with the way our user tests turned out.
